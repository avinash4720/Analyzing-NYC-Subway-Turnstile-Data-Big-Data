{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39718b1-1b6f-4581-b06f-cb72e63933ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:44:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://avinashs-mbp.lan:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8be800ce50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "# conf.set('spark.ui.proxyBase', '/user/' + 'Nishal Sundarraman' + '/proxy/4040')\n",
    "\n",
    "client = MongoClient()\n",
    "db = client.nm4074_BigData\n",
    "mtaPred = db[\"mtaPredictions\"]\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc)\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d7162e4-d23a-48d1-bd73-d68df9d5ac41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark\\\n",
    ".read\\\n",
    ".option(\"inferSchema\"\n",
    ", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(\"/Users/avinashvijay/Desktop/NYU/Big Data/project/data/MTA Data/Data/*.csv\")\n",
    "\n",
    "#df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d5c7d6b-4095-4ac1-ba03-dcae2c4e8a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- C/A: string (nullable = true)\n",
      " |-- UNIT: string (nullable = true)\n",
      " |-- SCP: string (nullable = true)\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- LINENAME: string (nullable = true)\n",
      " |-- DIVISION: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- TIME: timestamp (nullable = true)\n",
      " |-- DESC: string (nullable = true)\n",
      " |-- ENTRIES: integer (nullable = true)\n",
      " |-- EXITS                                                               : integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b7abb1-4a84-4f35-a676-fff80aee5a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, hour, col\n",
    "\n",
    "\n",
    "df = df.withColumn(\"Year\", split(df[\"DATE\"], \"/\")[2].alias(\"day\"))\n",
    "df = df.withColumn(\"Day\", split(df[\"DATE\"], \"/\")[1].alias(\"month\"))\n",
    "df = df.withColumn(\"Month\", split(df[\"DATE\"], \"/\")[0].alias(\"year\"))\n",
    "df = df.withColumn('Hour', hour(col('TIME')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea59846d-9f04-4da4-a952-92d4df52fd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"LINENAME\", outputCol=\"idx_linename\")\n",
    "\n",
    "encoder = OneHotEncoder(inputCol=\"idx_linename\", outputCol=\"encoded_linename\")\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, encoder])\n",
    "\n",
    "encoded_df = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567f1419-1958-427e-8976-800535826586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+--------+-------+--------+--------+----------+-------------------+-------+-------+--------------------------------------------------------------------+----+---+-----+----+------------+----------------+\n",
      "|_c0| C/A|UNIT|     SCP|STATION|LINENAME|DIVISION|      DATE|               TIME|   DESC|ENTRIES|EXITS                                                               |Year|Day|Month|Hour|idx_linename|encoded_linename|\n",
      "+---+----+----+--------+-------+--------+--------+----------+-------------------+-------+-------+--------------------------------------------------------------------+----+---+-----+----+------------+----------------+\n",
      "|  0|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/28/2023|2023-05-08 03:00:00|REGULAR|7823204|                                                             2779648|2023| 28|   01|   3|        87.0|(113,[87],[1.0])|\n",
      "|  1|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/28/2023|2023-05-08 07:00:00|REGULAR|7823209|                                                             2779660|2023| 28|   01|   7|        87.0|(113,[87],[1.0])|\n",
      "|  2|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/28/2023|2023-05-08 11:00:00|REGULAR|7823236|                                                             2779708|2023| 28|   01|  11|        87.0|(113,[87],[1.0])|\n",
      "|  3|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/28/2023|2023-05-08 15:00:00|REGULAR|7823309|                                                             2779758|2023| 28|   01|  15|        87.0|(113,[87],[1.0])|\n",
      "|  4|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/28/2023|2023-05-08 19:00:00|REGULAR|7823405|                                                             2779810|2023| 28|   01|  19|        87.0|(113,[87],[1.0])|\n",
      "|  5|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/28/2023|2023-05-08 23:00:00|REGULAR|7823467|                                                             2779838|2023| 28|   01|  23|        87.0|(113,[87],[1.0])|\n",
      "|  6|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/29/2023|2023-05-08 03:00:00|REGULAR|7823481|                                                             2779860|2023| 29|   01|   3|        87.0|(113,[87],[1.0])|\n",
      "|  7|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/29/2023|2023-05-08 07:00:00|REGULAR|7823485|                                                             2779866|2023| 29|   01|   7|        87.0|(113,[87],[1.0])|\n",
      "|  8|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/29/2023|2023-05-08 11:00:00|REGULAR|7823501|                                                             2779904|2023| 29|   01|  11|        87.0|(113,[87],[1.0])|\n",
      "|  9|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/29/2023|2023-05-08 15:00:00|REGULAR|7823558|                                                             2779941|2023| 29|   01|  15|        87.0|(113,[87],[1.0])|\n",
      "+---+----+----+--------+-------+--------+--------+----------+-------------------+-------+-------+--------------------------------------------------------------------+----+---+-----+----+------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d266917-7c45-4e78-a811-ef95a77aca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======>                                                  (8 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_15 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_11 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_14 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_13 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_10 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_9 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:29:14 WARN MemoryStore: Not enough space to cache rdd_13_8 in memory! (computed 13.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==============>                                          (16 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_19 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_23 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_20 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_22 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_21 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_16 in memory! (computed 20.7 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_17 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:29:21 WARN MemoryStore: Not enough space to cache rdd_13_18 in memory! (computed 24.2 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==============>                                         (16 + 10) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_30 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_26 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_24 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_29 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_28 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_25 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_31 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:27 WARN MemoryStore: Not enough space to cache rdd_13_27 in memory! (computed 24.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=============================>                           (32 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_32 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_35 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_37 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_38 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_33 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_39 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_34 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:29:35 WARN MemoryStore: Not enough space to cache rdd_13_36 in memory! (computed 24.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=====================================>                   (40 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_43 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_45 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_42 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_44 in memory! (computed 23.9 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_46 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_40 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_47 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:29:44 WARN MemoryStore: Not enough space to cache rdd_13_41 in memory! (computed 24.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:============================================>            (48 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:29:52 WARN MemoryStore: Not enough space to cache rdd_13_55 in memory! (computed 14.0 MiB so far)\n",
      "23/05/09 10:29:52 WARN MemoryStore: Not enough space to cache rdd_13_53 in memory! (computed 23.9 MiB so far)\n",
      "23/05/09 10:29:52 WARN MemoryStore: Not enough space to cache rdd_13_51 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:52 WARN MemoryStore: Not enough space to cache rdd_13_52 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:29:52 WARN MemoryStore: Not enough space to cache rdd_13_54 in memory! (computed 24.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.select('encoded_linename').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7736e5-3e3a-4d85-a945-f8de752cedba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:03 WARN MemoryStore: Not enough space to cache rdd_13_5 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:30:03 WARN MemoryStore: Not enough space to cache rdd_13_4 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:30:03 WARN MemoryStore: Not enough space to cache rdd_13_6 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 10:30:03 WARN MemoryStore: Not enough space to cache rdd_13_2 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:30:03 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                        (1 + 9) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_12 in memory! (computed 6.9 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_13 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_9 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_10 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_11 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_8 in memory! (computed 6.9 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_14 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 10:30:05 WARN MemoryStore: Not enough space to cache rdd_13_15 in memory! (computed 13.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:==============>                                         (16 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_19 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_22 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_21 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_18 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_17 in memory! (computed 13.9 MiB so far)\n",
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_23 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 10:30:07 WARN MemoryStore: Not enough space to cache rdd_13_16 in memory! (computed 20.7 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======================>                                 (24 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_24 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_29 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_30 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_28 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_25 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_31 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_26 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:10 WARN MemoryStore: Not enough space to cache rdd_13_27 in memory! (computed 7.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:======================>                                 (25 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_36 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_33 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_32 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_35 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_39 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_34 in memory! (computed 13.9 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_37 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:30:12 WARN MemoryStore: Not enough space to cache rdd_13_38 in memory! (computed 24.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:====================================>                   (40 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_44 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_42 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_46 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_43 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_40 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_47 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_45 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:30:14 WARN MemoryStore: Not enough space to cache rdd_13_41 in memory! (computed 24.1 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:============================================>           (48 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_50 in memory! (computed 13.8 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_55 in memory! (computed 24.2 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_51 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_53 in memory! (computed 23.9 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_49 in memory! (computed 24.1 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_52 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_54 in memory! (computed 24.0 MiB so far)\n",
      "23/05/09 10:30:16 WARN MemoryStore: Not enough space to cache rdd_13_48 in memory! (computed 24.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_df.select('LINENAME').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ff000-8904-44a9-926d-5834dc31b0e3",
   "metadata": {},
   "source": [
    "## Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06a2882b-47dc-4a78-9383-4342b7054292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79ecc68-5318-4c3c-b879-f49c16671bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.withColumn('dummy', lit(1))\n",
    "window = Window.partitionBy('dummy').orderBy('C/A', 'UNIT', 'SCP', 'DATE', 'TIME')\n",
    "\n",
    "encoded_df = encoded_df \\\n",
    "  .withColumn('last_entries', lag('ENTRIES', 1).over(window)) \\\n",
    "  .withColumn('last_exits', lag('EXITS                                                               ', 1).over(window))\n",
    "\n",
    "encoded_df = encoded_df \\\n",
    "  .withColumn('final_entries', when(encoded_df['ENTRIES'] >= encoded_df['last_entries'], encoded_df['ENTRIES'] - encoded_df['last_entries']).otherwise(encoded_df['ENTRIES'])) \\\n",
    "  .withColumn('final_exits', when(encoded_df['EXITS                                                               '] >= encoded_df['last_exits'], encoded_df['EXITS                                                               '] - encoded_df['last_exits']).otherwise(encoded_df['EXITS                                                               ']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4072ee-cc88-41d2-ad26-6e119df6e453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- C/A: string (nullable = true)\n",
      " |-- UNIT: string (nullable = true)\n",
      " |-- SCP: string (nullable = true)\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- LINENAME: string (nullable = true)\n",
      " |-- DIVISION: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- TIME: timestamp (nullable = true)\n",
      " |-- DESC: string (nullable = true)\n",
      " |-- ENTRIES: integer (nullable = true)\n",
      " |-- EXITS                                                               : integer (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Day: string (nullable = true)\n",
      " |-- Month: string (nullable = true)\n",
      " |-- Hour: integer (nullable = true)\n",
      " |-- idx_linename: double (nullable = false)\n",
      " |-- encoded_linename: vector (nullable = true)\n",
      " |-- dummy: integer (nullable = false)\n",
      " |-- last_entries: integer (nullable = true)\n",
      " |-- last_exits: integer (nullable = true)\n",
      " |-- final_entries: integer (nullable = true)\n",
      " |-- final_exits: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11c5819d-aef7-4873-9431-6c9f9d4df342",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.withColumn(\"Day\", col(\"Day\").cast(\"int\"))\n",
    "encoded_df = encoded_df.withColumn(\"Month\", col(\"Month\").cast(\"int\"))\n",
    "encoded_df = encoded_df.withColumn(\"Year\", col(\"Year\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e7dfb9d-f137-4cae-86ef-84a74453ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=============================>                            (4 + 4) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(encoded_df.select('idx_linename').distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da733237-69e7-428a-a2cd-8f6334aa0de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.fillna(0)\n",
    "encoded_df = encoded_df.withColumn('Food Traffic', col('final_entries')+col('final_exits'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4eaaed-aee2-4fde-bafa-87a51f91139f",
   "metadata": {},
   "source": [
    "## Corelation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c587fb6-4c04-4110-b4d2-a033c94c1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======>                                                  (8 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:42:25 WARN MemoryStore: Not enough space to cache rdd_13_10 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:25 WARN MemoryStore: Not enough space to cache rdd_13_15 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:25 WARN MemoryStore: Not enough space to cache rdd_13_14 in memory! (computed 3.5 MiB so far)\n",
      "23/05/09 11:42:25 WARN MemoryStore: Not enough space to cache rdd_13_9 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:25 WARN MemoryStore: Not enough space to cache rdd_13_13 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 11:42:25 WARN MemoryStore: Not enough space to cache rdd_13_8 in memory! (computed 6.9 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:==============>                                          (15 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_23 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_18 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_22 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_19 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_17 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_21 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_16 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:42:58 WARN MemoryStore: Not enough space to cache rdd_13_20 in memory! (computed 7.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:======================>                                  (24 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_24 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_28 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_25 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_29 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_27 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_26 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_31 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:20 WARN MemoryStore: Not enough space to cache rdd_13_30 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=============================>                           (32 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_32 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_37 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_38 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_39 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_33 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_34 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:43:47 WARN MemoryStore: Not enough space to cache rdd_13_35 in memory! (computed 7.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=====================================>                   (40 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_43 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_47 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_46 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_44 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_45 in memory! (computed 7.1 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_40 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_42 in memory! (computed 3.5 MiB so far)\n",
      "23/05/09 11:44:16 WARN MemoryStore: Not enough space to cache rdd_13_41 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:==========================================>              (46 + 9) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_49 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_51 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_48 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_52 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_50 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_53 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_13_54 in memory.\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_54 in memory! (computed 384.0 B so far)\n",
      "23/05/09 11:44:37 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_13_55 in memory.\n",
      "23/05/09 11:44:37 WARN MemoryStore: Not enough space to cache rdd_13_55 in memory! (computed 384.0 B so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=============================================>           (49 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:45:04 WARN MemoryStore: Not enough space to cache rdd_13_56 in memory! (computed 13.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================================================>     (55 + 6) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:45:06 WARN MemoryStore: Not enough space to cache rdd_13_60 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:45:06 WARN MemoryStore: Not enough space to cache rdd_13_57 in memory! (computed 3.5 MiB so far)\n",
      "23/05/09 11:45:06 WARN MemoryStore: Not enough space to cache rdd_13_58 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:06 WARN MemoryStore: Not enough space to cache rdd_13_59 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                         (0 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:45:18 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/09 11:45:18 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=======>                                                  (8 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:45:35 WARN MemoryStore: Not enough space to cache rdd_13_10 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:35 WARN MemoryStore: Not enough space to cache rdd_13_13 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:35 WARN MemoryStore: Not enough space to cache rdd_13_9 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:45:35 WARN MemoryStore: Not enough space to cache rdd_13_8 in memory! (computed 6.9 MiB so far)\n",
      "23/05/09 11:45:35 WARN MemoryStore: Not enough space to cache rdd_13_15 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:35 WARN MemoryStore: Not enough space to cache rdd_13_14 in memory! (computed 3.5 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============>                                          (16 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_18 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_23 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_19 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_21 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_16 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_22 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_17 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:45:59 WARN MemoryStore: Not enough space to cache rdd_13_20 in memory! (computed 7.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==============>                                         (16 + 10) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_28 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_29 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_24 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_26 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_13_30 in memory.\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_25 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_27 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_13_31 in memory.\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_30 in memory! (computed 384.0 B so far)\n",
      "23/05/09 11:46:21 WARN MemoryStore: Not enough space to cache rdd_13_31 in memory! (computed 384.0 B so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==========================>                              (28 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_37 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_35 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_32 in memory! (computed 7.0 MiB so far)\n",
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_34 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_33 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:39 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_13_38 in memory.\n",
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_38 in memory! (computed 384.0 B so far)\n",
      "23/05/09 11:46:39 WARN MemoryStore: Not enough space to cache rdd_13_39 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=====================================>                   (40 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_46 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_44 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_41 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_47 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_42 in memory! (computed 3.5 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_45 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_40 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:46:59 WARN MemoryStore: Not enough space to cache rdd_13_43 in memory! (computed 7.0 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==========================================>              (46 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_50 in memory! (computed 3.5 MiB so far)\n",
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_48 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_53 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_49 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_52 in memory! (computed 3.7 MiB so far)\n",
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_54 in memory! (computed 6.9 MiB so far)\n",
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_51 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:============================================>            (48 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:47:14 WARN MemoryStore: Not enough space to cache rdd_13_55 in memory! (computed 3.6 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=============================================>           (49 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:47:36 WARN MemoryStore: Not enough space to cache rdd_13_56 in memory! (computed 13.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:================================================>        (52 + 8) / 61]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 11:47:37 WARN MemoryStore: Not enough space to cache rdd_13_57 in memory! (computed 3.5 MiB so far)\n",
      "23/05/09 11:47:37 WARN MemoryStore: Not enough space to cache rdd_13_58 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:47:38 WARN MemoryStore: Not enough space to cache rdd_13_59 in memory! (computed 3.6 MiB so far)\n",
      "23/05/09 11:47:38 WARN MemoryStore: Not enough space to cache rdd_13_60 in memory! (computed 3.7 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseMatrix([[ 1.00000000e+00,  1.42682754e-02, -8.68141499e-03,\n",
      "              -4.82107167e-03,  4.61177235e-04],\n",
      "             [ 1.42682754e-02,  1.00000000e+00, -1.34808951e-01,\n",
      "              -7.03210967e-03,  8.60040228e-04],\n",
      "             [-8.68141499e-03, -1.34808951e-01,  1.00000000e+00,\n",
      "               1.68599635e-03, -5.05945428e-02],\n",
      "             [-4.82107167e-03, -7.03210967e-03,  1.68599635e-03,\n",
      "               1.00000000e+00, -1.12056630e-03],\n",
      "             [ 4.61177235e-04,  8.60040228e-04, -5.05945428e-02,\n",
      "              -1.12056630e-03,  1.00000000e+00]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour', 'idx_linename'], outputCol=\"features\")\n",
    "df_vector = assembler.transform(encoded_df)\n",
    "\n",
    "# compute the correlation matrix\n",
    "corr_matrix = Correlation.corr(df_vector, 'features').head()[0]\n",
    "\n",
    "# print the correlation matrix\n",
    "print(corr_matrix)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reshape the correlation matrix as a numpy array\n",
    "corr_matrix_array = np.array(corr_matrix.toArray())\n",
    "\n",
    "# plot the correlation matrix\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(corr_matrix_array, cmap='coolwarm')\n",
    "\n",
    "# add the colorbar\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e9f477-ff00-453f-8855-59a0c96aa6a7",
   "metadata": {},
   "source": [
    "## Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff30b60d-8748-4176-a764-74092da56709",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = encoded_df.filter((col('final_entries')<=1000) & (col('final_exits')<=1000) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8b010-d4a5-4284-8b15-540734c9230d",
   "metadata": {},
   "source": [
    "## 34th Street Herald Sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a66cfef-f261-4891-b9c5-271f2a7a84bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:48:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 18:48:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:====>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:48:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==============>                                          (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:48:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================>                                 (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:49:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===============================>                         (24 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:49:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================================> (42 + 1) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:49:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 18:49:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:====>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:49:46 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=============>                                           (10 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:49:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:=======================>                                 (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:50:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===============================>                         (24 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:50:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:52:56 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/05/09 18:52:56 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:52:56 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "23/05/09 18:52:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 18:52:57 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:53:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:==========>                                               (8 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:53:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=========================>                               (19 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:53:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:=================================>                       (25 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:53:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:56:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 18:56:17 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:>                                                        (0 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:56:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:==================>                                     (14 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:56:39 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:====================>                                   (16 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:56:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:57:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 310.184\n",
      "Coefficients: [0.12532990583272624,2.387113269902955,-46.5747575852593,26.474606779331562]\n",
      "Intercept: 94042.57892860155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour'], outputCol=\"features\")\n",
    "new_df = final_df.filter(df['STATION'] == '34 ST-HERALD SQ')\n",
    "new_df = assembler.transform(new_df)\n",
    "\n",
    "train, test = new_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Food Traffic\")\n",
    "lr.setRegParam(0.01)\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Food Traffic\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "\n",
    "message = {'stationName': '34 ST-HERALD SQ', 'x1': model.coefficients[0], 'x2': model.coefficients[1], 'x3': model.coefficients[2], 'x4': model.coefficients[3]}\n",
    "mtaPred.insert_one(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d5c01-bc67-432d-91c4-a05ed7888ba1",
   "metadata": {},
   "source": [
    "## Penn Station\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea45de3d-b443-4363-ae66-86cba25b951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:59:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 18:59:38 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==>                                                      (2 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:59:49 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===============>                                        (12 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 18:59:59 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================>                                 (17 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:00:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:00:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:======================================================> (42 + 1) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:00:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 19:00:37 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:00:48 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:================>                                       (13 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:00:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:=======================>                                (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:01:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:01:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:03:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:03:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====>                                                   (4 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:04:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:================>                                       (13 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:04:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=======================>                                (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:04:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:================================>                       (25 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:04:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:07:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 19:07:18 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:07:28 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=============>                                          (10 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:07:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:====================>                                   (16 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:07:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:===============================>                        (24 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:08:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 273.345\n",
      "Coefficients: [-0.028445231118806154,1.350438785352042,-48.72160804640406,19.886244692811545]\n",
      "Intercept: 98408.29150290073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour'], outputCol=\"features\")\n",
    "new_df = final_df.filter(df['STATION'] == '34 ST-PENN STA')\n",
    "new_df = assembler.transform(new_df)\n",
    "\n",
    "train, test = new_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Food Traffic\")\n",
    "lr.setRegParam(0.01)\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Food Traffic\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "\n",
    "message = {'stationName': '34 ST-PENN STA', 'x1': model.coefficients[0], 'x2': model.coefficients[1], 'x3': model.coefficients[2], 'x4': model.coefficients[3]}\n",
    "mtaPred.insert_one(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf84df5-5868-4495-8587-2dbc0fe84be1",
   "metadata": {},
   "source": [
    "## GRD CNTRL-42 ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a938ff7d-150d-40bd-9fb1-0b7cbd40954b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:10:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 19:10:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=====>                                                   (4 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:10:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:=============>                                          (10 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:11:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:========================>                               (19 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:11:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:===============================>                        (24 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:11:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:======================================================> (42 + 1) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:11:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:11:43 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:==>                                                      (2 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:11:53 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:==========>                                              (8 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:12:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:=======================>                                (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:12:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:12:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:15:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 19:15:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:15:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:15:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:=======================>                                (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:15:36 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:15:47 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:18:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 19:18:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:18:34 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:18:44 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:======================>                                 (17 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:18:54 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:=================================>                      (26 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:19:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 308.988\n",
      "Coefficients: [-0.182535214829987,-0.24886990367747416,-56.92190371807762,17.523539044046665]\n",
      "Intercept: 115007.53984680552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour'], outputCol=\"features\")\n",
    "new_df = final_df.filter(df['STATION'] == 'GRD CNTRL-42 ST')\n",
    "new_df = assembler.transform(new_df)\n",
    "\n",
    "train, test = new_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Food Traffic\")\n",
    "lr.setRegParam(0.01)\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Food Traffic\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "\n",
    "message = {'stationName': 'GRD CNTRL-42 ST', 'x1': model.coefficients[0], 'x2': model.coefficients[1], 'x3': model.coefficients[2], 'x4': model.coefficients[3]}\n",
    "mtaPred.insert_one(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2579d00-d73e-469d-9ed8-9fc765695c43",
   "metadata": {},
   "source": [
    "## 14 ST-UNION SQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2419fd55-616c-4634-bdfd-9858f6bdeda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:21:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:21:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:==========>                                              (8 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:21:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:22:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:======================>                                 (17 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:22:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:22:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:======================================================> (42 + 1) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:22:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:22:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:======>                                                  (5 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:22:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:===========>                                             (9 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:23:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:========================>                               (19 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:23:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 36:===============================>                        (24 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:23:23 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:26:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:26:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                        (0 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:26:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:26:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:====================>                                   (16 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:26:30 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:=================================>                      (26 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:26:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:29:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 19:29:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:29:31 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:29:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:======================>                                 (17 + 9) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:29:52 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 42:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:30:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 44:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 344.434\n",
      "Coefficients: [-0.5118582082291449,0.6747620927739875,-61.4850637103951,35.279712879311006]\n",
      "Intercept: 124140.98185376446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour'], outputCol=\"features\")\n",
    "new_df = final_df.filter(df['STATION'] == '14 ST-UNION SQ')\n",
    "new_df = assembler.transform(new_df)\n",
    "\n",
    "train, test = new_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Food Traffic\")\n",
    "lr.setRegParam(0.01)\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Food Traffic\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "\n",
    "message = {'stationName': '14 ST-UNION SQ', 'x1': model.coefficients[0], 'x2': model.coefficients[1], 'x3': model.coefficients[2], 'x4': model.coefficients[3]}\n",
    "mtaPred.insert_one(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3c5713-56e3-44ba-a6d3-d5780b3b0cd9",
   "metadata": {},
   "source": [
    "## 23 ST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2a3f06a-d1a1-4621-b5bd-73a85c929484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:32:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:32:41 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:==>                                                      (2 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:32:51 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:=============>                                          (10 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:33:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:======================>                                 (17 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:33:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:33:22 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 45:======================================================> (42 + 1) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:33:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:33:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:=====>                                                   (4 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:33:50 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:===============>                                        (12 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:34:00 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:======================>                                 (17 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:34:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:34:20 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:36:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:36:58 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:37:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:37:19 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:=======================>                                (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:37:29 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:37:40 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:40:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n",
      "23/05/09 19:40:24 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:40:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:==============>                                         (11 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:40:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:======================>                                 (17 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:40:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 19:41:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 275.161\n",
      "Coefficients: [-0.3290775762626256,-0.7102201463745217,-48.52416259427298,20.25624235710693]\n",
      "Intercept: 98011.47254883788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour'], outputCol=\"features\")\n",
    "new_df = final_df.filter(df['STATION'] == '23 ST')\n",
    "new_df = assembler.transform(new_df)\n",
    "\n",
    "train, test = new_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Food Traffic\")\n",
    "lr.setRegParam(0.01)\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Food Traffic\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n",
    "\n",
    "message = {'stationName': '23 ST', 'x1': model.coefficients[0], 'x2': model.coefficients[1], 'x3': model.coefficients[2], 'x4': model.coefficients[3]}\n",
    "mtaPred.insert_one(message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1bc2f-b437-49b4-8f47-8db508384b3e",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ebcfaa5-6b6e-45e1-9e22-3fb8bcc3f2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 34:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 20:43:41 WARN MemoryStore: Not enough space to cache rdd_139_0 in memory! (computed 153.8 MiB so far)\n",
      "23/05/07 20:43:41 WARN BlockManager: Persisting block rdd_139_0 to disk instead.\n",
      "23/05/07 20:43:52 WARN MemoryStore: Not enough space to cache rdd_139_0 in memory! (computed 246.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 37:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 20:44:00 WARN MemoryStore: Not enough space to cache rdd_139_0 in memory! (computed 246.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 40:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 20:44:06 WARN MemoryStore: Not enough space to cache rdd_139_0 in memory! (computed 246.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 43:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 20:44:13 WARN MemoryStore: Not enough space to cache rdd_139_0 in memory! (computed 246.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 20:44:19 WARN MemoryStore: Not enough space to cache rdd_139_0 in memory! (computed 246.8 MiB so far)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 127185548.68405624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour', 'encoded_linename'], outputCol=\"features\")\n",
    "new_data = assembler.transform(encoded_df)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_data, test_data = new_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Define model\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"final_entries\")\n",
    "\n",
    "# Train model\n",
    "model = dt.fit(train_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate model performance\n",
    "evaluator = RegressionEvaluator(labelCol=\"final_entries\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7cd08f-8e8b-4ced-8b44-535c15235019",
   "metadata": {},
   "source": [
    "## No of Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1e3b890-090e-4aa0-91ed-7eb6bea3cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "temp_df = spark\\\n",
    ".read\\\n",
    ".option(\"inferSchema\"\n",
    ", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(\"/Users/avinashvijay/Desktop/NYU/Big Data/project/data/MTA Data/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2a2c5c6-e387-4c7e-8dc3-f028a2cc8322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90011832"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce6c3e-2385-4dd8-aeb5-2360846b532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"Day\", \"Month\", \"Year\", 'Hour'], outputCol=\"features\")\n",
    "new_df = encoded_df.filter(df['STATION'] == '23 ST')\n",
    "new_df = assembler.transform(new_df)\n",
    "\n",
    "train, test = new_df.randomSplit([0.8, 0.2])\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Food Traffic\")\n",
    "lr.setRegParam(0.01)\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"Food Traffic\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)\n",
    "\n",
    "print(\"Coefficients: %s\" % str(model.coefficients))\n",
    "print(\"Intercept: %s\" % str(model.intercept))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1509826a-ea24-4197-bd6a-0a55e31d2144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 17:28:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2018.csv\n",
      "23/05/09 17:28:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:===>                                                     (3 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 17:28:25 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2019.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:===============>                                        (12 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 17:28:35 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:=======================>                                (18 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 17:28:45 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2021.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:================================>                       (25 + 8) / 43]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/09 17:28:55 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      " Schema: _c0, C/A, UNIT, SCP, STATION, LINENAME, DIVISION, DATE, TIME, DESC, ENTRIES, EXITS                                                               \n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///Users/avinashvijay/Desktop/NYU/Big%20Data/project/data/MTA%20Data/Data/2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----+--------+-------+--------+--------+----------+-------------------+-------+-------+--------------------------------------------------------------------+----+---+-----+----+------------+----------------+-----+------------+----------+-------------+-----------+------------+\n",
      "|    _c0| C/A|UNIT|     SCP|STATION|LINENAME|DIVISION|      DATE|               TIME|   DESC|ENTRIES|EXITS                                                               |Year|Day|Month|Hour|idx_linename|encoded_linename|dummy|last_entries|last_exits|final_entries|final_exits|Food Traffic|\n",
      "+-------+----+----+--------+-------+--------+--------+----------+-------------------+-------+-------+--------------------------------------------------------------------+----+---+-----+----+------------+----------------+-----+------------+----------+-------------+-----------+------------+\n",
      "|5922129|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2017|2023-05-09 03:00:00|REGULAR|5992718|                                                             2028585|2017|  1|    1|   3|        86.0|(113,[86],[1.0])|    1|           0|         0|      5992718|    2028585|     8021303|\n",
      "|5922130|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2017|2023-05-09 07:00:00|REGULAR|5992730|                                                             2028594|2017|  1|    1|   7|        86.0|(113,[86],[1.0])|    1|     5992718|   2028585|           12|          9|          21|\n",
      "|5922131|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2017|2023-05-09 11:00:00|REGULAR|5992776|                                                             2028636|2017|  1|    1|  11|        86.0|(113,[86],[1.0])|    1|     5992730|   2028594|           46|         42|          88|\n",
      "|5922132|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2017|2023-05-09 15:00:00|REGULAR|5992980|                                                             2028680|2017|  1|    1|  15|        86.0|(113,[86],[1.0])|    1|     5992776|   2028636|          204|         44|         248|\n",
      "|5922133|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2017|2023-05-09 19:00:00|REGULAR|5993301|                                                             2028728|2017|  1|    1|  19|        86.0|(113,[86],[1.0])|    1|     5992980|   2028680|          321|         48|         369|\n",
      "|5922134|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2017|2023-05-09 23:00:00|REGULAR|5993515|                                                             2028750|2017|  1|    1|  23|        86.0|(113,[86],[1.0])|    1|     5993301|   2028728|          214|         22|         236|\n",
      "| 793662|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2018|2023-05-09 03:00:00|REGULAR|6464475|                                                             2188055|2018|  1|    1|   3|        86.0|(113,[86],[1.0])|    1|     5993515|   2028750|       470960|     159305|      630265|\n",
      "| 793663|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2018|2023-05-09 07:00:00|REGULAR|6464491|                                                             2188064|2018|  1|    1|   7|        86.0|(113,[86],[1.0])|    1|     6464475|   2188055|           16|          9|          25|\n",
      "| 793664|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2018|2023-05-09 11:00:00|REGULAR|6464517|                                                             2188106|2018|  1|    1|  11|        86.0|(113,[86],[1.0])|    1|     6464491|   2188064|           26|         42|          68|\n",
      "| 793665|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2018|2023-05-09 15:00:00|REGULAR|6464623|                                                             2188146|2018|  1|    1|  15|        86.0|(113,[86],[1.0])|    1|     6464517|   2188106|          106|         40|         146|\n",
      "| 793666|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2018|2023-05-09 19:00:00|REGULAR|6464806|                                                             2188192|2018|  1|    1|  19|        86.0|(113,[86],[1.0])|    1|     6464623|   2188146|          183|         46|         229|\n",
      "| 793667|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2018|2023-05-09 23:00:00|REGULAR|6464907|                                                             2188209|2018|  1|    1|  23|        86.0|(113,[86],[1.0])|    1|     6464806|   2188192|          101|         17|         118|\n",
      "|8626275|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2019|2023-05-09 03:00:00|REGULAR|6891983|                                                             2336751|2019|  1|    1|   3|        86.0|(113,[86],[1.0])|    1|     6464907|   2188209|       427076|     148542|      575618|\n",
      "|8626276|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2019|2023-05-09 07:00:00|REGULAR|6891992|                                                             2336763|2019|  1|    1|   7|        86.0|(113,[86],[1.0])|    1|     6891983|   2336751|            9|         12|          21|\n",
      "|8626277|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2019|2023-05-09 11:00:00|REGULAR|6892033|                                                             2336808|2019|  1|    1|  11|        86.0|(113,[86],[1.0])|    1|     6891992|   2336763|           41|         45|          86|\n",
      "|8626278|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2019|2023-05-09 15:00:00|REGULAR|6892153|                                                             2336829|2019|  1|    1|  15|        86.0|(113,[86],[1.0])|    1|     6892033|   2336808|          120|         21|         141|\n",
      "|8626279|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2019|2023-05-09 19:00:00|REGULAR|6892299|                                                             2336870|2019|  1|    1|  19|        86.0|(113,[86],[1.0])|    1|     6892153|   2336829|          146|         41|         187|\n",
      "|8626280|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2019|2023-05-09 23:00:00|REGULAR|6892430|                                                             2336890|2019|  1|    1|  23|        86.0|(113,[86],[1.0])|    1|     6892299|   2336870|          131|         20|         151|\n",
      "|7921346|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2020|2023-05-09 03:00:00|REGULAR|7328037|                                                             2483731|2020|  1|    1|   3|        86.0|(113,[86],[1.0])|    1|     6892430|   2336890|       435607|     146841|      582448|\n",
      "|7921347|A002|R051|02-00-00|  59 ST| NQR456W|     BMT|01/01/2020|2023-05-09 07:00:00|REGULAR|7328044|                                                             2483742|2020|  1|    1|   7|        86.0|(113,[86],[1.0])|    1|     7328037|   2483731|            7|         11|          18|\n",
      "+-------+----+----+--------+-------+--------+--------+----------+-------------------+-------+-------+--------------------------------------------------------------------+----+---+-----+----+------------+----------------+-----+------------+----------+-------------+-----------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "284d95f4-0fa7-4749-8b76-d2e2d15a43bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_2023 = spark\\\n",
    ".read\\\n",
    ".option(\"inferSchema\"\n",
    ", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(\"/Users/avinashvijay/Desktop/NYU/Big Data/project/data/MTA Data/2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3a0f1f7-5401-4a87-af6f-e497b907a342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11173582"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2023.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "596e2a53-db03-48e9-a2e4-a5c81ee6a473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98013.87719298246"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11173582/114\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc16db-c26f-4cd0-a180-3ce6e29b781c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
